import random
from torch.utils.data import DataLoader
import torchvision
import torchtext
from config import *
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt

def get_image_datapath(image_dim, check_exist=True):
    if image_dim not in supported_image_dims:
        raise Exception("Unknown Image dim given")

    # dir_name = Path('binary_images/' + ORG_DATASET_ROOT_PATH + "_width_" + str(image_dim))
    # dir_name = Path('../tiny-image copy')
    dir_name = Path('../tiny-image2 copy')
    # dir_name = Path('../detection-image')

    if dir_name.exists():
        return dir_name.__str__()
    else:
        raise Exception("Data dir for Image dim {image_dim} missing".format(image_dim=image_dim))


def get_image_data_loaders(data_path=None, image_dim=64, train_split=0.8, batch_size=256,
                           convert_to_rgb=False, pretrained_image_dim=64, conv1d_image_dim_w=1024):
    train_split = train_split
    workers_count = min(int(CPU_COUNT * 0.80), batch_size)

    image_dim_h = image_dim
    image_dim_w = image_dim

    if image_dim == 0:
        # Conv1D case
        image_dim_h = 1
        image_dim_w = conv1d_image_dim_w

    transform = None
    batch_size = 5
    # 이미지에 색이 있는 경우
    if convert_to_rgb:
        transform = torchvision.transforms.Compose([
            torchvision.transforms.Resize((pretrained_image_dim, pretrained_image_dim)),
            torchvision.transforms.Lambda(lambda image: image.convert('RGB')),
            torchvision.transforms.ToTensor()
        ])
    # 이미지에 색이 없는 경우
    else:
        transform = torchvision.transforms.Compose([
            torchvision.transforms.Grayscale(num_output_channels=1),
            torchvision.transforms.Resize((image_dim_h, image_dim_w)),
            torchvision.transforms.ToTensor()
        ])

    data_path = (Path(data_path).resolve()).__str__()
    print(f'image dataset root_dir path: {data_path}')
    dataset = torchvision.datasets.ImageFolder(root=data_path, transform=transform)

    # for i, data in dataset:

    dataset_len = len(dataset)
    # dataset_len = 1000
    indices = list(range(dataset_len))
    random.shuffle(indices)
    print(f'Length of dataset: {dataset_len}', end=', ')
    print(f'Split rate for train: {train_split}')
    split = int(np.floor(train_split * dataset_len))

    #  loader에는 어떤 파일들이 선정되고 각 레이블의 번호가 입력되어 있다.
    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,
                                               sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[:split]),
                                               num_workers=workers_count)

    val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,
                                             sampler=torch.utils.data.sampler.SubsetRandomSampler(
                                                 indices[split:dataset_len]),
                                             num_workers=workers_count)

    train_set_len = len(train_loader) * batch_size
    val_set_len = len(val_loader) * batch_size
    class_names = dataset.classes

    return train_loader, val_loader, dataset_len, class_names