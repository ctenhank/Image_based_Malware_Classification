import argparse
from datetime import datetime
from models.models_utils import *
from models.model_trainers_testers import *
from models import *
from utils import *
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import sklearn.metrics
import sys
import traceback


def setup():
    current_time_str = str(datetime.now().strftime("%d-%b-%Y_%H_%M_%S"))
    LOG_DIR = os.path.join(LOG_MASTER_DIR, current_time_str)
    os.makedirs(LOG_DIR)
    return LOG_DIR


def execute_deep_feedforward_model(model_params, LOG_DIR):
    # result.write(f'Model params: {model_params}'))
    print(f'Model params: {model_params}')

    batch_size = model_params['batch_size']
    # batch_size = 256
    feature_type = model_params['feature_type']

    # 데이터 불러오기:
    # feature 타입이 이미지인 경우
    if feature_type == FEATURE_TYPE_IMAGE:
        # image_dim은 image dimension, 즉 해상도를 의미
        image_dim = model_params['image_dim']
        # 여기서 -1을 하는 이유가 뭐지? 
        # 배열이여서?
        conv1d_image_dim_w = -1
        # 해당 해상도의 image 데이터 불러옴
        # print(f'image dimension: {image_dim}')
        # print(f'batch size: {batch_size}')
        data_path = get_image_datapath(image_dim)
        if image_dim == 0:
            # conv1d models
            conv1d_image_dim_w = model_params['conv1d_image_dim_w']

        print(f'Loading image data')
        # result.write(f'Loading image data')
        train_loader, val_loader, dataset_len, class_names = get_image_data_loaders(data_path=data_path,
                                                                                    image_dim=image_dim,
                                                                                    batch_size=batch_size,
                                                                                    conv1d_image_dim_w=conv1d_image_dim_w,
                                                                                    train_split=model_params['split_rate'])

    train_set_len = len(train_loader) * batch_size
    val_set_len = len(val_loader) * batch_size
    num_of_classes = len(class_names)

    model_params['num_of_classes'] = num_of_classes
    model_params['class_names'] = class_names
    model_params['epochs'] = 20

    # print('breakpoint1')

    if feature_type == FEATURE_TYPE_IMAGE:
        # to 함수?
        # CUDA를 사용할 수 있으면 GPU로
        # 없으면 CPU로 실행하는 것을 의미
        model = create_deep_image_model(model_params).to(device)

    # print('breakpoint7')


    # nn.CrossEntropyLoss는 LogSoftmax와 NLLoss를 합친 것
    criterion = nn.CrossEntropyLoss().to(device)
    # print('breakpoint8')

    model, train_losses, train_accuracy = train_model(model=model, model_params=model_params, criterion=criterion,
                                                          train_loader=train_loader, log_dir=LOG_DIR)
    model.eval()
    # print('breakpoint9')
    test_accuracy, predicted, ground_truth = test_model(model=model, model_params=model_params, criterion=criterion,
                                                            val_loader=val_loader)
    # print('breakpoint10')
    model_params['train_accuracy'] = np.mean(train_accuracy)
    model_params['test_accuracy'] = np.mean(test_accuracy)

    print(f"Average Train accuracy: {model_params['train_accuracy']:7.4f}%")
    print(f"Average Test accuracy : {model_params['test_accuracy']:7.4f}%")
    # print('breakpoint11')
    save_model_results_to_log(model=model, model_params=model_params,
                              train_losses=train_losses, train_accuracy=train_accuracy,
                              predicted=predicted, ground_truth=ground_truth,
                              log_dir=LOG_DIR)
    # print('breakpoint12')


def process_deep_learning(experiment_types, LOG_DIR):
    for expr_type in experiment_types:
        """
        expr_type: 어떤 모델인지 확인하기 위한 변수
        DNN에서는 두 가지 경우가 있음
          1. Feedforward Deep
              1) ANN
              2) CNN1 ~ CNN5(디폴트는 CNN5)
                * CNN 모델들의 차이는 하이퍼파라미터에 따라 차이나는데, 마지막 CNN5는 opcode 길이도 추가
                * 모든 CNN을 비교분석 하고싶다면, models/models_util.py 함수 중,
                    get_deep_rnn_expr_list()의 파라미터 값 simple_list를 True로 변경
          2. RNN(이는 차후에 분석)
        """
        
        malware_expr_list = get_malware_experiments_list(expr_type)
        total_expr = len(malware_expr_list)

        final_results = []
        for num, ml in enumerate(malware_expr_list):
            if 'num_layers' in ml.keys():
                num_layers = ml['num_layers']
                if num_layers == 1:
                    ml['dropout'] = 0

            print_line()
            print(f'Executing : {ml["experiment_name"]} ({num + 1}/{total_expr})')
            print_line()
            try:
                if expr_type == DEEP_FF:
                    execute_deep_feedforward_model(ml, LOG_DIR)
            except Exception:
                print('failed')
                temp_dict = {'experiment_name': ml['experiment_name'],
                             'train_accuracy': 'failed',
                             'test_accuracy': 'failed'}
                print_line()
                print("FAILED")
                print(traceback.print_exc())
                print_line()
                print(sys.exc_info()[0])
                print_line()
            else:
                temp_dict = {'experiment_name': ml['experiment_name'],
                             'train_accuracy': ml['train_accuracy'],
                             'test_accuracy': ml['test_accuracy']}

            final_results.append(temp_dict)

        exp_results_filename = os.path.join(LOG_DIR, expr_type + '_' + EXPERIMENT_RESULTS)
        df = pd.DataFrame(final_results)
        expr_name = df['experiment_name']
        df.drop(['experiment_name'], axis=1, inplace=True)
        df.set_index(expr_name, drop=True, inplace=True)
        df.to_csv(exp_results_filename)
        save_models_metadata_to_log(malware_expr_list, LOG_DIR)


def main(LOG_DIR):
    deep_learning_models = []
    deep_learning_models.append(DEEP_FF)

    print_line()
    print(f'Starting Deep Learning Experiments to detect Malwares')
    print_line()
    process_deep_learning(deep_learning_models, LOG_DIR)
    print_line()
        


def print_banner(LOG_DIR):
    print_line()
    if use_cuda:
        print('Using GPU:', torch.cuda.get_device_name(torch.cuda.current_device()))
    else:
        print('Running on :', device)

    print(f'LOG_DIR = {LOG_DIR}')
    print_line()


if __name__ == '__main__':
    result = open('result_models.json', 'w+')
    LOG_DIR = setup()
    print_banner(LOG_DIR)
    main(LOG_DIR)
    print_banner(LOG_DIR)
